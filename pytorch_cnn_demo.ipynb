{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch cnn demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashleyyyyy567/Breast-Cancer-Classification/blob/master/pytorch_cnn_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPF97wJAK4ef"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9KPBho_LYN0"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_1orHaR_UJb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure, imshow, axis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SelruhXCLa5q"
      },
      "source": [
        "#### Experimental settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJwg2G14Eqp7"
      },
      "source": [
        "num_classes = 10 # number of output classes discrete range [0,9]\n",
        "num_epochs = 20 # number of times which the entire dataset is passed throughout the model\n",
        "batch_size = 64 # the size of input data took for one iteration\n",
        "lr = 1e-3 # size of step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5KQVujCLcjk"
      },
      "source": [
        "#### Download training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYg5w-KiEtP1"
      },
      "source": [
        "train_data = dsets.MNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_data = dsets.MNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C79EEDeLfWR"
      },
      "source": [
        "#### DataLoader example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDkyIPCpEwql"
      },
      "source": [
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7TNYXCiLiH0"
      },
      "source": [
        "#### Sample and view dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50AXe7nrGAKl"
      },
      "source": [
        "fig = figure(figsize=(30, 15))\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(1,10,i)\n",
        "    image, label = train_gen.dataset[i]\n",
        "    imshow(np.squeeze(image), cmap='gray')\n",
        "    a.set_title('label: {}'.format(label))\n",
        "    axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I48CY89Lmf7"
      },
      "source": [
        "#### Define neural network module using PyTorch nn api\n",
        "\n",
        "$$\n",
        "n_{\\textrm{out}} = \\textrm{Floor}\\left[\\frac{n_{\\textrm{in}}+2\\textrm{pad}-\\textrm{kernel size}}{\\textrm{stride}}\\right]\n",
        "$$\n",
        "where $n$ is the number of input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCDA6qItF2g_"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(Net,self).__init__()\n",
        "\n",
        "    self.conv_layers = nn.Sequential(\n",
        "        nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=0),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.fc_layers = nn.Sequential(\n",
        "        nn.Linear(int(10*((28-(5-1))/2)**2), num_classes),\n",
        "    )\n",
        "  \n",
        "  def forward(self,x):\n",
        "    out = self.conv_layers(x)\n",
        "    activations = out\n",
        "    out = out.view(-1, int(10*((28-(5-1))/2)**2))\n",
        "    out = self.fc_layers(out)\n",
        "    return out, activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJR5jZuL5QW"
      },
      "source": [
        "#### Instantiate network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acxnGh1nGvIh"
      },
      "source": [
        "net = Net(num_classes)\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hcZ2YynL-d6"
      },
      "source": [
        "#### Instantiate loss and optimizer objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1EpKs8rG9u1"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA3GsFfOMBa0"
      },
      "source": [
        "#### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyMdIpX0GEIh"
      },
      "source": [
        "tr_loss_hist = []\n",
        "val_loss_hist= []\n",
        "lamb = 1e-5\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  for i ,(images,labels) in enumerate(train_gen):\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs,_ = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    # L2 regularization\n",
        "    if True:\n",
        "      l2_reg = torch.tensor(0.).cuda()\n",
        "      for param in net.parameters():\n",
        "          if len(param.shape) > 1:\n",
        "            l2_reg += torch.norm(param,p='fro')\n",
        "          else:\n",
        "            l2_reg += torch.norm(param,p=2)\n",
        "      loss += lamb * l2_reg\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "      tqdm.write('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))\n",
        "  with torch.no_grad():\n",
        "    tr_images, tr_labels = next(iter(train_gen))\n",
        "    val_images, val_labels = next(iter(test_gen))\n",
        "    tr_output,_ = net(tr_images.cuda())\n",
        "    val_output,_ = net(val_images.cuda())\n",
        "    tr_loss = loss_function(tr_output, tr_labels.cuda())\n",
        "    val_loss = loss_function(val_output, val_labels.cuda())\n",
        "    tr_loss_hist.append(tr_loss.item())\n",
        "    val_loss_hist.append(val_loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptlTkEfw7oWq"
      },
      "source": [
        "#### Model persistence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPs70Whc7dyl"
      },
      "source": [
        "torch.save(net.state_dict(), './model.pt')\n",
        "\n",
        "net = Net(num_classes)\n",
        "net.load_state_dict(torch.load('./model.pt'))\n",
        "net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3CJI2q1FkUF"
      },
      "source": [
        "state_dict = torch.load('./model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUhEbBmgg5xi"
      },
      "source": [
        "#### Plot training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a1kGUqOg8M-"
      },
      "source": [
        "plt.plot(tr_loss_hist, label='training loss')\n",
        "plt.plot(val_loss_hist, label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI5F4wHUMC11"
      },
      "source": [
        "#### Testing loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rosJwXlmHAZg"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "incorrect_images = []\n",
        "for images,labels in test_gen:\n",
        "  images = images.cuda()\n",
        "  labels = labels.cuda()\n",
        "  \n",
        "  output,_ = net(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "  correct += (predicted == labels).sum()\n",
        "  if any (predicted!= labels):\n",
        "    incorrect_images.append(images.data[predicted != labels])\n",
        "  total += labels.size(0)\n",
        "\n",
        "incorrect_images = torch.vstack(incorrect_images).reshape((-1,28,28))\n",
        "print('Accuracy of the model: %.3f' %((correct)/(total+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPpQpREz2wV"
      },
      "source": [
        "incorrect_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeYNujhHYSpF"
      },
      "source": [
        "#### Visualize misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uamlCV5hQtoQ"
      },
      "source": [
        "fig = figure(figsize=(30, 15))\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(1,10,i)\n",
        "    image = incorrect_images[i]\n",
        "    output,activations = net(torch.unsqueeze(torch.unsqueeze(image, 0),0))\n",
        "    _, label = torch.max(output,1)\n",
        "\n",
        "    imshow(np.squeeze(image.cpu().reshape((28,28))), cmap='gray')\n",
        "    a.set_title('prediction: {}'.format(label.item()))\n",
        "    axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HC5nZcWmebj"
      },
      "source": [
        "### Investigating filter weights and activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JZS1fnCmpkC"
      },
      "source": [
        "first_layer_weight = net.conv_layers[0].weight.cpu().detach().numpy()\n",
        "first_layer_weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NBPSeeemrcr"
      },
      "source": [
        "fig = figure(figsize=(30, 15))\n",
        "plt.tight_layout()\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(2,10,i)\n",
        "    weight = first_layer_weight[i,0,:]\n",
        "    imshow(weight, cmap='gray')\n",
        "    axis('off')\n",
        "    \n",
        "fig = figure(figsize=(30, 15))\n",
        "plt.tight_layout()\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(2,10,i)\n",
        "    imshow(activations[0][i].detach().cpu().numpy(), cmap='gray')\n",
        "    axis('off')\n",
        "\n",
        "fig = figure(figsize=(30, 15))\n",
        "plt.tight_layout()\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(2,10,i)\n",
        "    amax = np.argmax(activations[0][i].detach().cpu().numpy())\n",
        "    amax = np.unravel_index(amax, activations[0][i].shape)\n",
        "    actimg = image.cpu().numpy()\n",
        "    minx,maxx = np.maximum(amax[0]*2-5,0),np.minimum(amax[0]*2+5,28)\n",
        "    miny,maxy = np.maximum(amax[1]*2-5,0),np.minimum(amax[1]*2+5,28)\n",
        "    actimg[minx:maxx, miny:maxy] += 1\n",
        "    imshow(actimg, cmap='gray')\n",
        "    axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l0w2bKtEOIl"
      },
      "source": [
        "activation_list = []\n",
        "for images,labels in test_gen:\n",
        "  images = images.cuda()\n",
        "  labels = labels.cuda()\n",
        "  _,activations = net(images)\n",
        "  activation_list.append(activations)\n",
        "\n",
        "testset_activations = torch.vstack(activation_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGMEVu627iNM"
      },
      "source": [
        "max_act = torch.argmax(torch.norm(testset_activations, dim=(-2,-1), p='fro'),dim=0)\n",
        "max_act_images = test_gen.dataset.data[max_act]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4_DtAyd8Izv"
      },
      "source": [
        "fig = figure(figsize=(30, 15))\n",
        "plt.tight_layout()\n",
        "for i in range(1,10):\n",
        "    a=fig.add_subplot(2,10,i)\n",
        "    imshow(max_act_images[i].detach().cpu().numpy(), cmap='gray')\n",
        "    axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSDg6su_V0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}